colnames.new <- colnames(XL)
colnames.old
XL
dim(XL)
length(unlist(groups))
is.null(colnames(X))
if (is.null(colnames(X))) {
colnames(X) <- paste0('var_', cov_ind)
}
cov_ind
if (is.null(colnames(X))) {
colnames(X) <- paste0('var_', 1:ncol(X))
}
colnames(X)
dimnames(p.values.combined) <- list(NULL, colnames(X)[cov_ind])
dimnames(p.values.combined)
# Create 4 groups
groups <- list(1:10, 30:40, 80:100, c(3,5,30,33,39))
X.old <- X
X.adjust_vars <- X.old[, adjust_vars]
X.new <- subset(X, select = -adjust_vars, drop = TRUE)
n.cov <- ncol(X.new)
# create an iterator
cov_ind <- setdiff(1:ncol(X), adjust_vars)
# Keep only variables that are included in groups
colnames.old <- colnames(X.old)
colnames.new <- colnames(X.new)
groups.old <- groups
groups.new <- lapply(groups.old, function(group) {
which(colnames.old[group] %in% colnames.new)
})
dim(X)
dim(X.old)
dim(X.new)
groups
groups.old
groups.new
colnames.new
colnames.old
colnames.old[group]
colnames.old[groups[[1]]]
colnames.new[groups[[1]]]
colnames.new
which(colnames.old[group] %in% colnames.new)
which(colnames.old[groups[[1]]] %in% colnames.new)
which(colnames.old[groups[[2]]] %in% colnames.new)
groups[2]
colnames.old[groups[[2]]]
colnames.new
colnames.old[groups[[2]]] %in% colnames.new
colnames.new[colnames.old[groups[[2]]] %in% colnames.new]
colnames.new[colnames.old[groups[[2]]]]
colnames.new %in% colnames.old[groups[[2]]]
which(colnames.new %in% colnames.old[groups[[2]]])
which(colnames.new %in% colnames.old[groups[[1]]])
groups.new <- lapply(groups.old, function(group) {
which(colnames.new %in% colnames.old[groups])
})
groups.old
colnames.old[groups]
groups.new <- lapply(groups.old, function(group) {
which(colnames.new %in% colnames.old[group])
})
groups.new
groups.old
cov_ind
colnames.new
dimnames(p.values.combined)
# Create 4 groups
groups <- list(1:10, 30:40, 80:100, c(3,5,30,33,39))
variables_in_groups <- do.call(c, groups)
variables_not_in_groups <- as.list(setdiff(cov_ind, variables_in_groups))
groups <- c(groups, variables_not_in_groups)
groups
groups
cov_ind
colnames.X <- colnames(X)
colnames.pvalue <- dimnames(p.values.combined)[[2]]
groups.pvalue <- lapply(groups, function(group) {
which(colnames.pvalue %in% colnames.X[group])
})
colnames.X
colnames.pvalue
groups
groups.pvalue
groups.new
artp.output <- sapply(groups.pvalue, function(group) {
# get the p values obtained while permutating for the current group
data <- t(as.matrix(p.values.combined[, group]))
# apply the ARTP to get the p-values for the group
ARTP(data, J = min(trunc.point, nrow(data)), n.permutations)
})
artp.output
dim(artp.output)
class(artp.output)
p.values.combined[, 1]
p.values.combined[, groups.pvalue[[1]]]
data <- t(as.matrix(p.values.combined[, groups.pvalue[[1]]])
)
data
res <- data.frame(
id = 1:length(groups),
group.size = sapply(groups, function(group) length(group)), # the group sizes
truncation.point = unlist(artp.output[1, ]), # the truncation points for each group
p = unlist(artp.output[2, ]) # the p-values associated with each group
)
res
devtools::check('..')
devtools::check('..')
devtools::check('..')
devtools::check('..')
devtools::load_all('..')
set.seed(1)
### Create a simple dataset
m <- 100
n <- 10000
X <- matrix(rbinom(m * n, 1, .05), ncol = m)
# Create 4 groups
groups <- list(1:10, 30:40, 80:100, c(3,5,30,33,39))
# Generate binary response given the groups
y <- sapply(1:n, function(i) {
x <- X[i, ]
lg <- -4 + 4*sum(x[c(3, 5)]) + 4*sum(x[c(30, 33, 39)])
py <- 1 / (1 + exp(-lg))
rbinom(1,1,py)
})
### Divide the simulated data in a train and test dataset
train_ind <- sort(sample(seq_len(n), size = floor(n/2)))
X_train = X[train_ind, ]
X_test = X[-train_ind, ]
y_train = y[train_ind]
y_test = y[-train_ind]
### Fit the data
fit <- artp.fit(X_train, y_train, groups = groups, verbose = TRUE)
### Predict
prediction <- artp.predict(fit, X_test, alpha = 0.1)
fit$p.values.group
fit$groups.pvalue
fit$groups
fit$groups.pvalue
fit$p.values.group
### Fit the data
fit <- artp.fit(X_train, y_train, trunc.point = 5, groups = groups, verbose = TRUE)
devtools::load_all('..')
### Fit the data
fit <- artp.fit(X_train, y_train, groups = groups, verbose = TRUE)
### Predict
prediction <- artp.predict(fit, X_test, alpha = 0.1)
fit$p.values.group
devtools::check('..')
fit$p.values.group
### Set seed
set.seed(43)
### Create a simple dataset
m <- 100
n <- 10000
X <- matrix(rbinom(m * n, 1, .05), ncol = m)
# Create 4 groups
groups <- list(1:10, 30:40, 80:100, c(3,5,30,33,39))
# Generate binary response given the groups
y <- sapply(1:n, function(i) {
x <- X[i, ]
lg <- -4 + 4*sum(x[c(3, 5)]) + 4*sum(x[c(30, 33, 39)])
py <- 1 / (1 + exp(-lg))
rbinom(1,1,py)
})
### Divide the simulated data in a train and test dataset
train_ind <- sort(sample(seq_len(n), size = floor(n/2)))
X_train = X[train_ind, ]
X_test = X[-train_ind, ]
y_train = y[train_ind]
y_test = y[-train_ind]
### Fit the data
fit <- artp.fit(X_train, y_train, groups = groups, verbose = TRUE)
fit$p.values.group
### Predict
prediction <- artp.predict(fit, X_test, alpha = 0.5)
### Predict
prediction <- artp.predict(fit, X_test, alpha = 0.6)
prediction
table(prediction$y.hat)
table(prediction$y.hat, y_test)
table(y_test)
table(prediction$y.hat)
selected.groups <- fit$p.values.group %>% dplyr::filter(p <= 0.5)
selected.groups
selected.groups <- fit$p.values.group %>% dplyr::filter(p <= 0.6)
selected.groups
selected.groups$id
group.id = 1
# get the old data for the current group
group <- fit$groups.new[[group.id]]
data.old <- fit$X[, group]
# get the new data of the current group
data.new <- X_test[, group]
data.old
# fit the model on the old data for that group alone
model <- stats::glm(y.old ~ data.old, family = stats::binomial("logit"))
# get the old y values. Used to fit the model for each group
y.old <- fit$y
# fit the model on the old data for that group alone
model <- stats::glm(y.old ~ data.old, family = stats::binomial("logit"))
# predict whether or not the outcome is 1 given the new data of the current group
y.new <- stats::predict(model, newdata = data.frame(data.new), type = "response")
# decide whether TRUE or FALSE
y.new <- (y.new > .5)
y.new
selected.groups
group.id = 59
group <- fit$groups.new[[group.id]]
data.old <- fit$X[, group]
# get the new data of the current group
data.new <- X_test[, group]
# fit the model on the old data for that group alone
model <- stats::glm(y.old ~ data.old, family = stats::binomial("logit"))
# predict whether or not the outcome is 1 given the new data of the current group
y.new <- stats::predict(model, newdata = data.frame(data.new), type = "response")
# decide whether TRUE or FALSE
y.new <- (y.new > .5)
y.new
alpha = 0.6
y.old <- fit$y
X.old <- fit$X
groups <- fit$groups.new # the grouping
# select the groups that are 'significant'
selected.groups <- fit$p.values.group %>% dplyr::filter(p <= alpha)
# no significant groups at all
if (nrow(selected.groups) == 0) {
stop("no significant groups found")
}
selected.groups
ncol(data.old)
data.old <- data.frame(y.old, X.old[, group])
ncol(data.old)
data.old
names(groups)
# predict for each observation the value of y
y.prob.per.group <- sapply(selected.groups$id, function(group.id) {
# get the old data for the current group
group <- groups[[group.id]]
data.old <- X.old[, group]
data.old <- data.frame(y.old, X.old[, group])
# if(ncol(data.old) == 2){names(data.old)[2] <- "X1"}
# get the new data of the current group
data.new <- X.new[, group]
# fit the model on the old data for that group alone
model <- stats::glm(y.old ~ data.old, family = stats::binomial("logit"))
# predict whether or not the outcome is 1 given the new data of the current group
y.new <- stats::predict(model, newdata = data.frame(data.new), type = "response")
# decide whether TRUE or FALSE
y.new <- (y.new > .5)
})
source('~/bips_devel/task13_realdata/lib/ARTPredict/R/predict.R')
# predict for each observation the value of y
y.prob.per.group <- sapply(selected.groups$id, function(group.id) {
# get the old data for the current group
group <- groups[[group.id]]
data.old <- X.old[, group]
# data.old <- data.frame(y.old, X.old[, group])
# if(ncol(data.old) == 2){names(data.old)[2] <- "X1"}
# get the new data of the current group
data.new <- X.new[, group]
# fit the model on the old data for that group alone
model <- stats::glm(y.old ~ data.old, family = stats::binomial("logit"))
# predict whether or not the outcome is 1 given the new data of the current group
y.new <- stats::predict(model, newdata = data.frame(data.new), type = "response")
# decide whether TRUE or FALSE
y.new <- (y.new > .5)
})
X.new = X_test
# predict for each observation the value of y
y.prob.per.group <- sapply(selected.groups$id, function(group.id) {
# get the old data for the current group
group <- groups[[group.id]]
data.old <- X.old[, group]
# data.old <- data.frame(y.old, X.old[, group])
# if(ncol(data.old) == 2){names(data.old)[2] <- "X1"}
# get the new data of the current group
data.new <- X.new[, group]
# fit the model on the old data for that group alone
model <- stats::glm(y.old ~ data.old, family = stats::binomial("logit"))
# predict whether or not the outcome is 1 given the new data of the current group
y.new <- stats::predict(model, newdata = data.frame(data.new), type = "response")
# decide whether TRUE or FALSE
y.new <- (y.new > .5)
})
str( y.prob.per.group)
dim(y_test)
length(y_test)
length(y_train)
# probabilities of y being one
y.group <- rowSums(y.prob.per.group)
y.group
length(y.group)
# decide whether TRUE or FALSE
y.hat <- as.numeric((y.group > 1))
y.hat
out <- list(selected.groups = selected.groups, y.group = y.group, y.hat = y.hat)
out$y.group
assess_results <- function(response, labels) {
P <- sum(labels)
N <- sum(!labels)
TP <- sum(response & labels)
TN <- sum(!response & !labels)
FP <- sum(response & !labels)
FN <- sum(!response & labels)
# recall or tpr or sensitivity
recall <- TP / (TP + FN)
precision <- TP / (TP + FP)
specifity <- TN / (TN + FP)
fpr <- FP / (TN + FP)
fdr <- FP / (TP + FP)
accuracy <- (TP + TN) / (TP + TN + FP + FN)
f1score <- 2 * ((precision * recall) / (precision + recall))
# f1scoreb <- 2*TP / (2*TP + FP + FN)
prc_baseline <- P / (P + N)
aucs <- precrec::auc(curves =
precrec::evalmod(scores = response, labels = labels)
)[[4]]
roc_auc <- aucs[1]
prc_auc <- aucs[2]
## Generate an sscurve object that contains ROC and Precision-Recall curves
## already calculated AUC for the whole graph
# or
# auc_prc <- subset(auc(curves = sscurves), curvetypes == "PRC")[[4]]
data.frame(
list(
recall = recall,
precision = precision,
specifity = specifity,
fpr = fpr,
fdr = fdr,
accuracy = accuracy,
f1score = f1score,
roc_auc = roc_auc,
prc_baseline = prc_baseline,
prc_auc = prc_auc
)
)
}
assess_results(y.hat, y_test)
set.seed(43)
### Create a simple dataset
m <- 100
n <- 10000
X <- matrix(rbinom(m * n, 1, .05), ncol = m)
# Create 4 groups
groups <- list(1:10, 30:40, 80:100, c(3,5,30,33,39))
# Generate binary response given the groups
y <- sapply(1:n, function(i) {
x <- X[i, ]
lg <- -4 + 4*sum(x[c(3, 5)]) + 4*sum(x[c(30, 33, 39)])
py <- 1 / (1 + exp(-lg))
rbinom(1,1,py)
})
devtools::load_all('..')
rm(list = c("artp.predict", "groups", "n"))
devtools::load_all('..')
train_ind <- sort(sample(seq_len(n), size = floor(n/2)))
X_train = X[train_ind, ]
X_test = X[-train_ind, ]
y_train = y[train_ind]
y_test = y[-train_ind]
### Fit the data
fit <- artp.fit(X_train, y_train, groups = groups, verbose = TRUE)
groups
# Create 4 groups
groups <- list(1:10, 30:40, 80:100, c(3,5,30,33,39))
### Fit the data
fit <- artp.fit(X_train, y_train, groups = groups, verbose = TRUE)
fit$groups
fit$groups[1:5]
groups[1:4]
fit$groups.new
fit$groups.new[1:5]
fit$p.values.group
### Predict
prediction <- artp.predict(fit, X_test, alpha = 0.6)
table(prediction$y.hat, y_test)
debug(artp.predict)
### Predict
prediction <- artp.predict(fit, X_test, alpha = 0.6)
table(prediction$y.hat, y_test)
selected.groups
group.id = 1
# get the old data for the current group
group <- groups[[group.id]]
data.old <- X.old[, c(adjust_vars, group)]
data.old
dim(data.old)
fit$adjust_vars
undebug()
undebug(artp.predict)
library(devtools)
load_all('..')
rm(list = c("groups"))
load_all('..')
set.seed(43)
### Create a simple dataset
m <- 100
n <- 10000
X <- matrix(rbinom(m * n, 1, .05), ncol = m)
# Create 4 groups
groups <- list(1:10, 30:40, 80:100, c(3,5,30,33,39))
# Generate binary response given the groups
y <- sapply(1:n, function(i) {
x <- X[i, ]
lg <- -4 + 4*sum(x[c(3, 5)]) + 4*sum(x[c(30, 33, 39)])
py <- 1 / (1 + exp(-lg))
rbinom(1,1,py)
})
### Divide the simulated data in a train and test dataset
train_ind <- sort(sample(seq_len(n), size = floor(n/2)))
X_train = X[train_ind, ]
X_test = X[-train_ind, ]
y_train = y[train_ind]
y_test = y[-train_ind]
### Fit the data
fit <- artp.fit(X_train, y_train, groups = groups, verbose = TRUE)
### Predict
prediction <- artp.predict(fit, X_test, alpha = 0.6)
table(prediction$y.hat, y_test)
fit$groups
fit$groups.new
groups
fit2 <- artp.fit(X_train, y_train, adjust_vars = adjust_vars, groups = groups, verbose = TRUE)
prediction2 <- artp.predict(fit2, X_test, alpha = 0.6)
set.seed(43)
### Create a simple dataset
m <- 100
n <- 10000
X <- matrix(rbinom(m * n, 1, .05), ncol = m)
# Create 4 groups
groups <- list(1:10, 30:40, 80:100, c(3,5,30,33,39))
# Generate binary response given the groups
y <- sapply(1:n, function(i) {
x <- X[i, ]
lg <- -4 + 4*sum(x[c(3, 5)]) + 4*sum(x[c(30, 33, 39)])
py <- 1 / (1 + exp(-lg))
rbinom(1,1,py)
})
### Divide the simulated data in a train and test dataset
train_ind <- sort(sample(seq_len(n), size = floor(n/2)))
X_train = X[train_ind, ]
X_test = X[-train_ind, ]
y_train = y[train_ind]
y_test = y[-train_ind]
### Fit the data
fit <- artp.fit(X_train, y_train, groups = groups, verbose = TRUE)
### Predict
prediction <- artp.predict(fit, X_test, alpha = 0.6)
table(prediction$y.hat, y_test)
adjust_vars <- c(22, 23, 50)
fit2 <- artp.fit(X_train, y_train, adjust_vars = adjust_vars, groups = groups, verbose = TRUE)
fit2$p.values.group
fit$p.values.group
fit2$p.values.group
fit2$groups
fit2$groups.new
fit1$groups.new
fit$groups.new
fit1$groups.new
fit2$groups.new
fit2$groups
fit2$groups.new
fit2$groups
unlist(fit2$groups)))
unlist(fit2$groups))
unlist(fit2$groups)
unlist(fit2$groups.new)
load_all('..')
rm(list = c("groups", "n"))
load_all('..')
adjust_vars <- c(22, 23, 50)
fit2 <- artp.fit(X_train, y_train, adjust_vars = adjust_vars, groups = groups, verbose = TRUE)
prediction2 <- artp.predict(fit2, X_test, alpha = 0.6)
table(prediction2$y.hat, y_test)
m <- 100
n <- 10000
X <- matrix(rbinom(m * n, 1, .05), ncol = m)
# Create 4 groups
groups <- list(1:10, 30:40, 80:100, c(3,5,30,33,39))
# Generate binary response given the groups
y <- sapply(1:n, function(i) {
x <- X[i, ]
lg <- -4 + 4*sum(x[c(3, 5)]) + 4*sum(x[c(30, 33, 39)])
py <- 1 / (1 + exp(-lg))
rbinom(1,1,py)
})
### Divide the simulated data in a train and test dataset
train_ind <- sort(sample(seq_len(n), size = floor(n/2)))
X_train = X[train_ind, ]
X_test = X[-train_ind, ]
y_train = y[train_ind]
y_test = y[-train_ind]
adjust_vars <- c(22, 23, 50)
fit2 <- artp.fit(X_train, y_train, adjust_vars = adjust_vars, groups = groups, verbose = TRUE)
prediction2 <- artp.predict(fit2, X_test, alpha = 0.6)
table(prediction2$y.hat, y_test)
assess_results(prediction2$y.hat, y_test)
assess_results(prediction$y.hat, y_test)
system.time({
fit <- artp.fit(X_train, y_train, groups = groups, verbose = TRUE)
prediction <- artp.predict(fit, X_test, alpha = 0.6)
})
table(prediction$y.hat, y_test)
table(prediction2$y.hat, y_test)
system.time({
fit <- artp.fit(X_train, y_train, adjust_vars = adjust_vars, groups = groups, verbose = TRUE)
prediction <- artp.predict(fit, X_test, alpha = 0.6)
})
q()
